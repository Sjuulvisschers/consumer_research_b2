---
title: "Assignment_b2"
output: html_document
date: "2024-05-14"
---
#setup of libraries and loading the data
> First, we load the data into R. The columns have already been renamed while transforming the csv file. 

```{r}
library(readr)
library(dplyr)
library(tidyverse)
library(tidyr)
library(ggplot2)
library(psych)
library(car)

df <- read_delim("CR24 Spring class survey raw data.csv", delim = ";", locale = locale(decimal_mark = ","))

```

#transforming the data
> We proceed by transforming the "money as time worked" donations to a value in euro's. In the csv file, the donation columns for all groups were called 'donation'. Sine R can't proceed multiple columns with the same name, these columns have been named "donation...9", "donation...16", "donation...23" and "donation...30". In our dataset, the columns "donation...9" and "donation...16" refer to the "money as time worked" conditions. In the code below, we transform these variables by multiplying them with the hourly wage of the respondents. By doing this, we create the donation value in euro's. 

```{r}

df <- df %>% 
  mutate(donation...9 = donation...9*hourly_wage,
         donation...16 = donation...16*hourly_wage)
```

> After transforming the "money as time worked" variable, we proceed by storing all the values for the different treatmens into the same column. Since the last column of the dataframe specifies the treatment, we can safely merge these columns since they represent the same measurements. The measurements vary based on the treatment of the respondent. 

```{r}

df <- df %>%
  unite(donation, donation...9, donation...16, donation...23, donation...30, na.rm = TRUE) %>%
  unite(significant_self, 'significant _self...10', 'significant _self...17', 'significant _self...24', 'significant _self...31', na.rm = TRUE) %>%
  unite(values_self, values_self...11, values_self...18, values_self...25, values_self...32, na.rm = TRUE) %>%
  unite(reflection_self, reflection_self...12, reflection_self...19, reflection_self...26, reflection_self...33, na.rm = TRUE) %>%
  unite(control, control...13, control...20, control...27, control...34, na.rm = TRUE) %>%
  unite(shape_utilize, shape_utilize...14, shape_utilize...21, shape_utilize...28, shape_utilize...35, na.rm = TRUE) %>%
  unite(involvement, involvement...15, involvement...22, involvement...29, involvement...36, na.rm = TRUE)


```

> After inspecting the data, we observe that the donation column is processed as a character variable, even though it should be processed as a numeric value. We modify this in the code below. 

```{r}
df <- df %>%
  mutate(donation = as.numeric(donation))

```

>After cleaning the data, we will create new columns for our mediating variables ("control" and "self-representativeness"). We do this by taking the average of the columns that correspond with these mediating variables. Both variables are currently measured based on three different columns. We transform these columns in order to better interpret the result when doing our analyses. 

```{r}
# Convert columns to numeric if they are not already
df <- df %>%
  mutate(
    control = as.numeric(control),
    shape_utilize = as.numeric(shape_utilize),
    involvement = as.numeric(involvement),
    significant_self = as.numeric(significant_self),
    values_self = as.numeric(values_self),
    reflection_self = as.numeric(reflection_self)
  )

# Calculate the mean of multiple columns
df <- df %>%
  mutate(avg_control = rowMeans(select(., c(control, shape_utilize, involvement)), na.rm = TRUE))


df <- df %>% 
  mutate(avg_representativeness = rowMeans(select(., c(significant_self, values_self, reflection_self)), na.rm = TRUE))

```

#making the dummies for time and framing
> Next, we are making two dummy variables so we can analyze the time-framed donations seperately from the long versus short term framing. 

```{r}
df <- df %>%
  mutate(immediate_dummy = as.integer(grepl("immediate", condition, ignore.case = TRUE)))

df <- df %>%
  mutate(timeframe_dummy = as.integer(grepl("time", condition, ignore.case = TRUE)))

```

#deleting the outliers

> In the code snippet below, we delete all the rows with an hourly wage higher than 1000 euros. ## we have to ask if this is correct or if we need a statistical way to determine what the outliers are.


```{r}

df <- df %>%
  filter(hourly_wage <= 1000)

```

> Now that we have cleaned the raw data, we start by checking if the randomization of the groups went well. We check for variables that are not influenced by the experiment. These variables are hourly wage, age and gender.

```{r}
lm_hourly_wage <- lm(hourly_wage ~ condition, df)
summary(lm_hourly_wage)

lm_age <- lm(age ~ condition, df)
summary(lm_age)

lm_gender <- lm(gender ~ condition, df)
summary(lm_gender)
```
> For intepretation of the results, it is important to know that the MoneyAsTimeWorkedLongterm condition is taken as the baseline. For hourly_wage, we conclude that the p values are not significant and thus that there are no differences between the different conditions. For age, the MoneyLongterm respondents are on average 5 years older. For gender, we can see that there is a slight significant difference for the MoneyImmediate condition.

> Next, we check the reliability of the scales used in the experiment by computing the cronbach's alpha of those measurement scales

```{r}

cronbach_variables <- c("significant_self", "values_self", "reflection_self", "control", "shape_utilize", "involvement", "trust")
cronbach_data <- df[cronbach_variables]

alpha <- alpha(cronbach_data)
print(alpha)

```
> When checking the output, it is visibile that all of the measurement scales report a raw_alpha above 0.8. This means that the scales used in the experiment are reliable. 

> We continue by checking assumptions before starting on our statistical analyses. First, we use the shapiro-wilk test to check if the results are normally distributed. 

```{r}
normality_results <- df %>%
  group_by(condition) %>%
  summarise(shapiro_test = list(shapiro.test(donation))) %>%
  mutate(shapiro_p_value = map_dbl(shapiro_test, ~ .x$p.value))

print(normality_results)
```
> All of the conditions report a significant p value regarding the normal distribution of the donations. This means that we reject the null-hypothesis, and thus meaning that the results are not normally distributed. 

```{r}
levene_test_result <- leveneTest(donation ~ condition, data = df)
print(levene_test_result)

```
> If the p-value from Levene's test is less than your chosen significance level (e.g., 0.05), you reject the null hypothesis, suggesting evidence of heteroscedasticity. So in this case, with a p-value of 0.02308, we can conclude that there is no evidence of homoscedasticity.


